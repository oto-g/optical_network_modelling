{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huawei Research France\n",
    "\n",
    "## Optical network modelling RAMP: cascading regressors\n",
    "\n",
    "### Predict the output of a 32-channel optical network from its input and side information about the sequence of network components\n",
    "\n",
    "_Balázs Kégl, Ludovic Dos Santos, Hartmut Hafermann (Huawei Research, Noah's Ark and Optical Laboratories, France)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Building system models and simulators is a relatively new application area of machine learning. These models can replace expensive experimentation and accelerate design. This year's Huawei France hackathon falls into this category: we will ask participants to learn a model of optical networks from (real) data taken in our Optical Lab. It is a **32-output nonlinear regression problem**, with non-classical challenges:\n",
    "1. **Transfer learning**: the training and test data will be different: at training we will provide data measured at internal points of the network, whereas we will test the models only for the full cascades, taken on a network with different characteristics from the training network.\n",
    "2. **Non-standard input**: besides input-output data, we will also provide variable-length side information about the network components which may greatly help the transfer from the training network to the test network.\n",
    "3. **Scoring metrics** will be a nonstandard measure of the relative prediction error that covers 99% test instances.\n",
    "\n",
    "### Context\n",
    "\n",
    "In optical transmission links, information is transmitted through optical fibers. The available transmission bandwidth is equally divided into a fixed number of slots or channels, 32 in this data challenge. Each channel can be used to transmit a beam of laser light at a fixed frequency, modulated by an information carrying signal, such that it occupies its assigned bandwidth. Each of these channels can be used to independently transmit information through the fiber.\n",
    "\n",
    "Even though modern fibers are highly transparent, the **loss of signal strength** is not negligible and can be as high as a factor of 100 = 20[dB](https://en.wikipedia.org/wiki/Decibel) for 100km of fiber. Fiber transmission links therefore typically consist of a **cascade of alternating optical amplifiers and fibers**. Optical amplifiers compensate for the losses by amplifying the optical signal directly inside the fiber, without the need to convert it into an electrical signal. One of the most widely used type of amplifier is the [Erbium-doped fiber amplifier (EDFA)](https://en.wikipedia.org/wiki/Optical_amplifier#Erbium-doped_optical_fiber_amplifiers). The optical link considered here consists of EDFAs, [Single mode fibers (SMFs)](https://en.wikipedia.org/wiki/Single-mode_optical_fiber) and variable optical attenuators (VOAs). The dashed lines in the following figure indicate the positions at which the signal is measured.\n",
    "<img src=\"https://raw.githubusercontent.com/ramp-kits/optical_network_modelling/2977eff1ac82349c2a130e89157e2e9db6a79d6a/link.png\">\n",
    "\n",
    "An EDFA implements a **32-input 32-output function**. Computer models of this function are highly useful when telecom providers design  optical networks since these models allow them to optimize the network before building it. In principle, EDFA amplifies its 32 input signals linearly, controlled by two parameters (set by the operator of the network), its nominal gain (the factor by which the signal is amplified on average) and nominal tilt (the factor by which the gain differs for leftmost and rightmost channel). In practice, the **amplification is nonlinear** and it also **depends on which channels are switched on and off**. Generalizing to unseen on/off configurations is important since network operators regularly add or drop channels according to transmission demand. There is no simple physical model of this combinatorial function, thus the aim of our project: explore using machine learning techniques that can be learned on a small subsample of the combinatorial space.\n",
    "\n",
    "Similar to an EDFA, a fiber is a nonlinear 32-input 32-output function whose response depends on which channels are switched on and off. The VOAs reduce the power of each channel by the same factor. They simply model the fact that in real optical links losses can occur, for example through poor splices (where two fibers are fused together). Here for simplicty we treat the composition of fiber and VOA as one entity. \n",
    "\n",
    "### The data\n",
    "\n",
    "The data is taken from lab measurements of the channel power in the cascaded link shown in the figure above. For the purpose of this RAMP, we can abstract the transmission cascade as a concatenation of eight modules:\n",
    "<img src=\"https://raw.githubusercontent.com/ramp-kits/optical_network_modelling/2977eff1ac82349c2a130e89157e2e9db6a79d6a/cascade.png\">\n",
    "Each module is either an EDFA or an SMF (fiber+VOA), described by a small metadata vector whose format depends on the module type. Each **training instance will be a subcascade** $(i,j)$ with input signal $P_i \\in \\mathbb{R}^{32}$ and output signal $P_j \\in \\mathbb{R}^{32}$ and a sequence of module metadata $(m_{i+1}, \\ldots, m_j)$. Each **test instance will be a full cascade** $(i=0,j=8)$ with input signal $P_0 \\in \\mathbb{R}^{32}$ and output signal $P_8 \\in \\mathbb{R}^{32}$ and a sequence of module metadata $(m_1, \\ldots, m_8)$. \n",
    "\n",
    "Each component of the vectors $P_j$ represents the power of the corresponding channel. Since the measured power at the entry and exit of each module differs by large factors, each channel was normalized to its power measured in the configuration where all channels are on. Powers are given on linear scale (not in dB). The values are therefore close to unity.\n",
    "\n",
    "For each module, the metadata is a vector with two values. For an EDFA, these are the nominal gain and nominal tilt, $m_i=[G_i, T_i]$ for $i$ odd, both measured in dB. The fibers in this dataset are of the same type and length. For the SMF module, the metadata are the factors by which the channels are attenuated in the VOA before or after the fiber, measured in dB: $m_i=[\\alpha_i^\\text{in}, \\alpha_i^\\text{out}]$ ($i$ even). The absence of a VOA corresponds to 0 dB. The channel power at the entrance of the fiber can in principle be calculated by dividing the power at the entrance of the module by $10^{\\alpha^\\text{in}/10}$. The power at the exit of the fiber is correspondingly obtained by multiplying by $10^{\\alpha^\\text{out}/10}$.\n",
    "\n",
    "To mimic real-life scenarios, the module metadata of the test cascade will be different from the \n",
    "module metadata of the training cascade (although the module types in the sequence will be the same). Each training and test instance will be generated by a random channel on/off configuration, cascaded through the network (so subcascade instances will not be independent). Again, training and test configurations will be different.\n",
    "\n",
    "### The scoring metrics\n",
    "\n",
    "We will report a classical RMSE score on the submissions, but the official ranking score will be EM99, which represents an error margin (the uncertainty in the prediction) within which 99% of the test cases fall. Specifically, it is given by the 99th percentile of the relative errors of the test predictions, measured in dB. All the metrics are only computed over channels which are switched on (non-zero components of the $P_i$).\n",
    "\n",
    "\n",
    "## Competition rules\n",
    "\n",
    "The rules may be adjusted before the start of the challenge, November 4 2020.\n",
    "\n",
    "[//]: # \"* Submissions will be trained on a time series of roughly 5000 time steps and tested on a time series of roughly 20000 time steps.\" \n",
    "* The competition will end on November 13, 2020 at 18h UTC (20h in Paris).\n",
    "* The competitive phase will be followed by a collaborative phase when participants may (and encouraged to) reuse and combine each other's code.\n",
    "* The final results will be announced at the closing ceremony on November 18. We will also ask top teams to present their approaches at the event.\n",
    "* All models will be trained on the same cloud server allowing 4 CPUs (with shared memory of 128GB RAM).\n",
    "* Participants will be given a total of 20 machine hours (per cross-validation fold). Submissions of a given participant will be ordered by submission timestamp. We will make an attempt to train all submissions, but starting from (and including) the first submission that makes the participant's total training time exceed 20 hours, all submissions will be disqualified from the competition (but can enter into the collaborative phase). Testing time will not count towards the limit. Training time will be displayed on the leaderboard for all submissions, rounded to second. If a submission raises an exception, its training time will not count towards the total.\n",
    "* There is a timeout of 1 day between submissions that did not raise an exception.\n",
    "* Submissions submitted after the end of the competition will not qualify for prizes.\n",
    "* The public leaderboard will display validation scores running a cross-validation. The official scores will be calculated on the hidden test set and will be published after the closing of the competition. We will rank submissions according to their EM99 score.\n",
    "* The organizers will do their best so that the provided backend runs flawlessly. We will communicate with participants in case of concerns and will try to resolve all issues, but we reserve the right to make unilateral decisions in specific cases, not covered by this set of minimal rules.\n",
    "* The organizers reserve the right to disqualify any participant found to violate the fair competitive spirit of the challenge. Possible reasons, without being exhaustive, are multiple accounts, attempts to access the test data, etc.\n",
    "* Participants can form teams outside the platform before submitting any model individually, and submit on a single team account. Participating in more than one team at the same time is against the \"no multiple accounts\" rule, so, if discovered, may lead to disqualification. Before signing up, teams should communicate their composition and team name to BeMyApp.\n",
    "* Participants retain copyright on their submitted code and grant reuse under BSD 3-Clause License.\n",
    "\n",
    "Participants accept these rules automatically when making a submission at the RAMP site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "Besides the usual pydata libraries, you will need to install `ramp-workflow` from the advanced branch:\n",
    "```\n",
    "pip install git+https://github.com/paris-saclay-cds/ramp-workflow.git@advanced\n",
    "```\n",
    "\n",
    "\n",
    "It will install the `rampwf` library and the `ramp-test` script that you can use to check your submission before submitting. You do not need to know this package for participating in the challenge, but it could be useful to take a look at the [documentation](https://paris-saclay-cds.github.io/ramp-docs/ramp-workflow/advanced/index.html) if you would like to know what happens when we test your model, especially the [RAMP execution](https://paris-saclay-cds.github.io/ramp-docs/ramp-workflow/advanced/scoring.html) page to understand `ramp-test`, and the [commands](https://paris-saclay-cds.github.io/ramp-docs/ramp-workflow/advanced/command_line.html) to understand the different command line options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rampwf as rw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read `problem.py` so you can have an access to the same interface as the testing script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = rw.utils.assert_read_problem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data\n",
    "\n",
    "First take the public data set from the Slack team #optical_network_challenge channel (join by [clicking here](https://join.slack.com/t/huaweiramp/shared_invite/zt-i5hqij3l-ufzyUJgKNJA407sWNB1QDA)) and unzip it to create `data/c1..c4`. \n",
    "\n",
    "Read the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = problem.get_train_data()\n",
    "X_test, y_test = problem.get_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data is a list of thruples of metadata, input power, and campaign index. The metadata is a sequence of desciptors of the network elements of the subcascade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([('EDFA', [24.0, 20.0]), ('SMF', [5.6, 0])]),\n",
       "       list([0.9854011268786588, 0.9579909333275516, 0.9874405077601779, 0.966566146485512, 0.9784920440057496, 0.9726006367972836, 0.9843132422152838, 0.9784334877724056, 0.9709820621986954, 0.9820604922371035, 0.9826946765531455, 0.9773055594854204, 0.968574860637684, 0.9762821604505046, 0.975065053383652, 0.975329686757004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       "       1], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data contains all subcascades of campaigns 1 and 2, plus some full cascades from campaigns 3 and 4. The test data contains the rest of the full cascades from campaigns 3 and 4. The reason for this setup is the following. In real life when a network is built, we will be able to have end-to-end measurements on the full network but not on its subcascades. In addition, we will have a large number of laboratory measurements on various subcascades, but the components of these lab networks will not have the same metadata as the components of the real network. In the challenge, the training campaigns represent the lab measurements and the test campaigns represent the end-to-end field measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training campaigns = [1 2 3 4]\n",
      "test campaigns = [3 4]\n",
      "training sequence lengths = [1 2 3 4 5 6 7 8]\n",
      "test sequence lengths = [8]\n",
      "training sequence lengths from test campaigns = [8]\n"
     ]
    }
   ],
   "source": [
    "print('training campaigns = {}'.format(np.unique([x[2] for x in X_train])))\n",
    "print('test campaigns = {}'.format(np.unique([x[2] for x in X_test])))\n",
    "print('training sequence lengths = {}'.format(np.unique([len(x[0]) for x in X_train])))\n",
    "print('test sequence lengths = {}'.format(np.unique([len(x[0]) for x in X_test])))\n",
    "print('training sequence lengths from test campaigns = {}'.format(\n",
    "    np.unique([len(x[0]) for x in X_train if x[2] in problem._test_campaigns])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the test only contains full cascades, the training set is much larger than the test set, but it contains only a very small number of instances that come from the same distribution as the test set. Also note that the training subcascades also come from a small number of full cascades of the training campaigns; the information in these subcascades is redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size = 23055\n",
      "test size = 1213\n",
      "number of training full cascades from the same distribution as the test set = 303\n",
      "number of full cascades from the training campaigns = 632\n"
     ]
    }
   ],
   "source": [
    "print('training size = {}'.format(len(X_train)))\n",
    "print('test size = {}'.format(len(X_test)))\n",
    "print('number of training full cascades from the same distribution '\n",
    "      'as the test set = {}'.format(len([x for x in X_train if x[2] in problem._test_campaigns])))\n",
    "print('number of full cascades from the training campaigns = {}'.format(\n",
    "    len([x for x in X_train if x[2] in problem._train_campaigns and len(x[0]) == 8])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second element of each instance is the actual input power to the subcascades, an array of 32 real numbers. The target corresponds to the output of the subcascade on the same channels. In each instance, we turned on about a third of the channels, the rest are zeros. The actual values in the arrays are factors wrt a mean power so the overall mean of input and output values is about 1. We will measure the performance of the predictors only on channels that were turned on. The overall standard deviation of the nonzero outputs is an upper bound of the RMSE of a predictor. Returning the input as the output is also a good baseline: it is slightly better than returning the mean on the training set (dominated by shorter subcascades) but not on the test set that contains only long full cascades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean occupation of channels (power != 0): 0.323546952938625\n",
      "Mean input power factor of nonzero channels = 1.0167000697991586\n",
      "Std input power factor of nonzero channels = 0.0647956525418062\n",
      "Mean output power factor of nonzero channels = 1.0452292762288091\n",
      "Std output power factor of nonzero channels = 0.1288248003299997\n",
      "RMSE of the identity function on nonzero channels = 0.10789475221344981\n"
     ]
    }
   ],
   "source": [
    "channel_input_train = np.array([x[1] for x in X_train])\n",
    "n_train = len(channel_input_train)\n",
    "mask_nonzero_train = channel_input_train > 0\n",
    "print('Mean occupation of channels (power != 0): {}'.format(\n",
    "    np.sum(mask_nonzero_train) / (problem._NB_CHANNELS * n_train)))\n",
    "print('Mean input power factor of nonzero channels = {}'.format(\n",
    "    channel_input_train[mask_nonzero_train].mean()))\n",
    "print('Std input power factor of nonzero channels = {}'.format(\n",
    "    channel_input_train[mask_nonzero_train].std()))\n",
    "print('Mean output power factor of nonzero channels = {}'.format(\n",
    "    y_train[mask_nonzero_train].mean()))\n",
    "print('Std output power factor of nonzero channels = {}'.format(\n",
    "    y_train[mask_nonzero_train].std()))\n",
    "print('RMSE of the identity function on nonzero channels = {}'.format(\n",
    "    np.sqrt(np.mean((channel_input_train[mask_nonzero_train] -\n",
    "                     y_train[mask_nonzero_train]) ** 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean occupation of channels (power != 0): 0.3230626545754328\n",
      "Mean input power factor of nonzero channels = 1.0122318368841638\n",
      "Std input power factor of nonzero channels = 0.042492824657587844\n",
      "Mean output power factor of nonzero channels = 1.029272143408915\n",
      "Std output power factor of nonzero channels = 0.15197441257292613\n",
      "RMSE of the identity function on nonzero channels = 0.16637156577695347\n"
     ]
    }
   ],
   "source": [
    "channel_input_test = np.array([x[1] for x in X_test])\n",
    "n_test = len(channel_input_test)\n",
    "mask_nonzero_test = channel_input_test > 0\n",
    "print('Mean occupation of channels (power != 0): {}'.format(\n",
    "    np.sum(mask_nonzero_test) / (problem._NB_CHANNELS * n_test)))\n",
    "print('Mean input power factor of nonzero channels = {}'.format(\n",
    "    channel_input_test[mask_nonzero_test].mean()))\n",
    "print('Std input power factor of nonzero channels = {}'.format(\n",
    "    channel_input_test[mask_nonzero_test].std()))\n",
    "print('Mean output power factor of nonzero channels = {}'.format(\n",
    "    y_test[mask_nonzero_test].mean()))\n",
    "print('Std output power factor of nonzero channels = {}'.format(\n",
    "    y_test[mask_nonzero_test].std()))\n",
    "print('RMSE of the identity function on nonzero channels = {}'.format(\n",
    "    np.sqrt(np.mean((channel_input_test[mask_nonzero_test] -\n",
    "                     y_test[mask_nonzero_test]) ** 2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prediction task\n",
    "\n",
    "You can load here the regressor implemented in the starting kit. It is a simple linear regressor that ignores the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load submissions/starting_kit/regressor.py\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "class Regressor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_array = np.array([np.array(X_i) for X_i in X[:, 1]])\n",
    "        self.reg = Ridge(alpha=1)\n",
    "        self.reg.fit(X_array, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_array = np.array([np.array(X_i) for X_i in X[:, 1]])\n",
    "        return self.reg.predict(X_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can train your submission and obtain test predictions using the same protocol as our training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_workflow = problem.workflow.train_submission('submissions/starting_kit', X_train, y_train)\n",
    "y_test_pred = problem.workflow.test_submission(trained_workflow, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The scores\n",
    "\n",
    "We compute three scores on the predictions. All scores are implemented in `problem.py` so you can look at the precise definitions there. All scores take into consideration only channels that are \"on\" in the particular instance. **All scores check the positivity of all predictions and return $\\infty$ if any of the predictions are negative.**\n",
    "\n",
    "EM99 is the 99 percentile of the relative error measured in decibel. MEM is the worst relative error measured in decibel. RMSE is the classical root mean squared error (except that it is also only computed on \"on\" channels).\n",
    "\n",
    "**The official score of the competition is EM99.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "em99_score = problem.score_types[0]\n",
    "rmse_score = problem.score_types[1]\n",
    "mem_score = problem.score_types[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM99 test score = 1.2808269708777709\n",
      "RMSE test score = 0.12475812286907513\n",
      "MEM test score = 2.376883475779602\n"
     ]
    }
   ],
   "source": [
    "print('EM99 test score = {}'.format(em99_score(y_test, y_test_pred)))\n",
    "print('RMSE test score = {}'.format(rmse_score(y_test, y_test_pred)))\n",
    "print('MEM test score = {}'.format(mem_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cross validation scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validation follows the same scheme as the train/test cut (see `problem.get_cv`): only (part) of the test campaign full cascades are in the validation sets and the rest of the test campaign instances plus a part of the training subcascades are in the training sets. You are free to play with both the train/test cut and the cross-validation when developing your models but be aware that we will use the same scheme on the official server as the one in the RAMP kit (on a different set of four campaigns that will not be available to you).\n",
    "\n",
    "The following cell goes through the same steps as the official evaluation script (`ramp-test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training EM99 on fold 0 = 1.096709749334698\n",
      "validation EM99 on fold 0 = 1.2291169010842582\n",
      "test EM99 on fold 0 = 1.2843604038060734\n",
      "training EM99 on fold 1 = 1.1078058921349596\n",
      "validation EM99 on fold 1 = 1.2841345341739479\n",
      "test EM99 on fold 1 = 1.2764197042868608\n",
      "training EM99 on fold 2 = 1.0913384768485284\n",
      "validation EM99 on fold 2 = 1.2792855072522518\n",
      "test EM99 on fold 2 = 1.280730271669307\n",
      "training EM99 on fold 3 = 1.0989618938773276\n",
      "validation EM99 on fold 3 = 1.2151060503006859\n",
      "test EM99 on fold 3 = 1.2912051839696272\n",
      "training EM99 on fold 4 = 1.1307055522166911\n",
      "validation EM99 on fold 4 = 1.2585370688329733\n",
      "test EM99 on fold 4 = 1.2781598166718113\n",
      "training EM99 on fold 5 = 1.0997655190735045\n",
      "validation EM99 on fold 5 = 1.2262019614883615\n",
      "test EM99 on fold 5 = 1.2857076289178684\n",
      "training EM99 on fold 6 = 1.1228302433652817\n",
      "validation EM99 on fold 6 = 1.2739918097896585\n",
      "test EM99 on fold 6 = 1.2789111456373359\n",
      "training EM99 on fold 7 = 1.1058643401979855\n",
      "validation EM99 on fold 7 = 1.2668517798856997\n",
      "test EM99 on fold 7 = 1.2844187133538956\n"
     ]
    }
   ],
   "source": [
    "splits = problem.get_cv(X_train, y_train)\n",
    "y_test_preds = []\n",
    "for fold_i, (train_is, valid_is) in enumerate(splits):\n",
    "    trained_workflow = problem.workflow.train_submission(\n",
    "        'submissions/starting_kit', X_train, y_train, train_is)\n",
    "    y_train_pred = problem.workflow.test_submission(trained_workflow, X_train[train_is])\n",
    "    y_valid_pred = problem.workflow.test_submission(trained_workflow, X_train[valid_is])\n",
    "    y_test_pred = problem.workflow.test_submission(trained_workflow, X_test)\n",
    "    print('training EM99 on fold {} = {}'.format(\n",
    "        fold_i, em99_score(y_train[train_is], y_train_pred)))\n",
    "    print('validation EM99 on fold {} = {}'.format(\n",
    "        fold_i, em99_score(y_train[valid_is], y_valid_pred)))\n",
    "    print('test EM99 on fold {} = {}'.format(\n",
    "        fold_i, em99_score(y_test, y_test_pred)))\n",
    "    y_test_preds.append(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute both the mean test score and the score of bagging your eight models. The official ranking will be detemined by the bagged test score (on different data sets from the ones you have). Your public score will be the bagged validation score (the averaging is [slightly more complicated](https://github.com/paris-saclay-cds/ramp-workflow/blob/master/rampwf/utils/combine.py#L56) since we need to take care of the cross validation masks properly). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean EM99 score = 0.12482309289565047\n",
      "Bagged EM99 score = 0.12480803802205302\n"
     ]
    }
   ],
   "source": [
    "bagged_y_pred = np.array(y_test_preds).mean(axis=0)\n",
    "print('Mean EM99 score = {}'.format(\n",
    "    np.mean([em99_score(y_test, y_test_pred) for y_test_pred in y_test_preds])))\n",
    "print('Bagged EM99 score = {}'.format(\n",
    "    em99_score(y_test, np.array(y_test_preds).mean(axis=0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example submissions\n",
    "\n",
    "Besides the starting kit implementing a linear regressor and the identity \n",
    "regressor, we provide you simple neural net based submissions in PyTorch, \n",
    "to get you started.\n",
    "Even if they are implemented in PyTorch and that you choose to go with an other\n",
    "library (TensorFlow, XGBoost, scikit-learn, ...)\n",
    "going through those examples might help. For those not familiar with it but \n",
    "willing to use this library consider this \n",
    "[tutorial](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).\n",
    "\n",
    "Note that those submissions are not fully hyperparameters-optimized and do not\n",
    "come with every possible Deep Learning tricks. Feel free to play with it\n",
    "locally.\n",
    "There is no need to submit them since their respective score are already in the\n",
    "leaderboard.\n",
    "In the following we will look at each of them to see some important points,\n",
    "for data format explanations and statistics please go to the data section.\n",
    "The following cells are made from some non executable \n",
    "code extract of the submissions to emphasis on important parts.\n",
    "\n",
    "### A simple Multi-Layer Perceptron\n",
    "\n",
    "This model is submitted under `submission/single_mlp/regressor.py`.\n",
    "This model take as input the input power ```p_in``` of the cascade and outputs\n",
    "the estimated output power without considering any meta data\n",
    "such as the cascade length or the feature of the optical modules. \n",
    "\n",
    "We define your Regressor as a PyTorch model defining the modules in the\n",
    "```__init__()``` function. It consists of two fully connected layers with an\n",
    "hidden size of 128. It takes as input the 32 channel input power vector and outputs a\n",
    "32 channel output power prediction. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def __init__(self):\n",
    "    super(Regressor, self).__init__()\n",
    "    # Definition of the modules of the model\n",
    "    # Two fully connected layers\n",
    "    self.fc0 = torch.nn.Linear(32, 128)\n",
    "    self.fc1 = torch.nn.Linear(128, 32)\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then implement its corresponding forward function adding a ```tanh```\n",
    "activation function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def forward(self, p_in):\n",
    "    # Compute the output of the model using a tanh activation function\n",
    "    p_out = self.fc1(torch.tanh(self.fc0(p_in)))\n",
    "    # Return positive values when evaluating the model\n",
    "    return p_out if self.training else relu(p_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that when the model is in evaluation mode (calling self.train() sets\n",
    "```self.training``` to ```True```, and calling ```self.eval()``` sets it to\n",
    "```False```) we clip the values to be positive. Outputting some negative values\n",
    "when predicting will end up with ```inf``` scores. This clipping should be\n",
    "done even if using other library.\n",
    "\n",
    "For those familiar with PyTorch, the ```fit``` RAMP function corresponds to a\n",
    "somehow classic learning scheme.  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fit(self, X, y):\n",
    "    # Turn on training mode\n",
    "    self.train()\n",
    "    # Get data and create train data loaders\n",
    "    data_as_list = [\n",
    "        [torch.tensor(p_in).float(), torch.tensor(p_out).float()]\n",
    "        for (_, p_in, _), p_out in zip(X, y)]\n",
    "    train_loader = torch.utils.data.DataLoader(data_as_list,\n",
    "                                               batch_size=128)\n",
    "    # Instantiate criterion and optimizer\n",
    "    crit = torch.nn.MSELoss()\n",
    "    opt = torch.optim.Adam(self.parameters())\n",
    "\n",
    "    # Training loop\n",
    "    for e in range(100):\n",
    "        for p_in, p_out in train_loader:\n",
    "            opt.zero_grad()\n",
    "            preds = self(p_in)\n",
    "            # Since the evaluation is only done for on-channels it\n",
    "            # helps the optimization to only backpropagate through them.\n",
    "            on_chan = p_in != 0\n",
    "            on_preds = torch.mul(on_chan, preds)\n",
    "            on_p_out = torch.mul(on_chan, p_out)\n",
    "            loss = crit(on_preds, on_p_out)\n",
    "            loss.backward()\n",
    "            opt.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We format the data to feed easily a PyTorch ```DataLoader``` in order to\n",
    "iterate among the training examples. Then we define our criterion\n",
    "(here an ```MSELoss```) and our optimizer (here ```Adam```).\n",
    "\n",
    "Note that for this model, since the RAMP scores consider only channels that are\n",
    "on, backpropagating only through on channels seems to bring better results.\n",
    "\n",
    "Finally, the RAMP ````predict``` function is just a forward pass of the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "    # Turn on evaluation mode\n",
    "    self.eval()\n",
    "    # No ground truth when predicting\n",
    "    p_in = torch.stack([torch.tensor(p_in).float() for _, p_in, _ in X])\n",
    "    preds = self(p_in).detach().numpy()\n",
    "    return preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cascading MLPs\n",
    "\n",
    "The second example we provide should help you cascade module wise models\n",
    "and use some of the meta data included in ```X``` (all but the campaign\n",
    "identifier).\n",
    "The model we built consist in learning a specific MLP for each module present\n",
    "in the training set (there is no unseen modules in the test set) that take as\n",
    "input ```p_in``` and the features of the module and output some predictions.\n",
    "\n",
    "To ease the comprehension of the code and making it easily reusable to you we\n",
    "define the PyTorch model outside the RAMP Regressor class, but we could have\n",
    "defined the model with hard coded parameters as we did for the previous MLP. \n",
    "\n",
    "This model is submitted under `submission/cascade_mlp/regressor.py`.\n",
    "\n",
    "\n",
    "First let's define our PyTorch model that consists of a list of MLPs, one\n",
    "for each optical module type. The optical module information is listed into\n",
    "```mod_info``` that is defined in the RAMP ```fit``` function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PyTorchModel(torch.nn.Module):\n",
    "    def __init__(self, mod_info):\n",
    "        super(PyTorchModel, self).__init__()\n",
    "        self.mod_info = mod_info\n",
    "        # Construct as many MLPs as modules present in the data\n",
    "        self.MLPs = torch.nn.ModuleList(\n",
    "            [MLP(m[\"nb_feat\"]) for m in self.mod_info])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "During the forward of this model we need to check the cascade's length and the\n",
    "optical modules present in order to apply (or not) the corresponding MLP.\n",
    "We compute a mask ```msk``` that corresponds to cascades for which optical\n",
    "modules are left and the current one having the same identifier as the current\n",
    "MLP. We then update the value of ```p_out``` and return it when we end up \n",
    "predicting all cascades output power."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def forward(self, mod_id_seq, mod_feat_seq, p_in):\n",
    "    seq_len = torch.tensor(list(map(len, mod_feat_seq)))\n",
    "    p_out = p_in\n",
    "    max_nb_mod = max(seq_len)\n",
    "    for n in range(max_nb_mod):\n",
    "        for i, mlp in enumerate(self.MLPs):\n",
    "            msk = torch.mul(mod_id_seq[:, n] == i, seq_len > n)\n",
    "            if msk.any():\n",
    "                feats = torch.stack(\n",
    "                    [f[n] for i, f in enumerate(mod_feat_seq) if msk[i]])\n",
    "                p_out[msk] = mlp(torch.cat([p_out[msk], feats], dim=-1))\n",
    "    # Return positive values when evaluating the model\n",
    "    return p_out if self.training else relu(p_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we have defined the model outside the Regressor class, the instantiation\n",
    "of the model is done while calling the RAMP ```fit``` function. We first read\n",
    "the data to retrieve some important information ```mod_info``` and then\n",
    "instantiate our model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fit(self, X, y):\n",
    "    # Retrieve some information about the modules from the data\n",
    "    all_mods = set(\n",
    "        [((\"type\", mod[0]), (\"nb_feat\", len(mod[1]))) for seq, _, _ in X\n",
    "         for mod in seq])\n",
    "    mod_info = [dict(m) for m in all_mods]\n",
    "    self.mod_id = {mod[\"type\"]: i for i, mod in enumerate(mod_info)}\n",
    "\n",
    "    # Instantiate the PyTorch model\n",
    "    self.model = self.Model(mod_info)\n",
    "    ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The remaining difference between this fit and the previous one is the\n",
    "formatting of the data we feed the ```DataLoader``` with that now includes meta\n",
    "information about the module."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_list = [{\"mod_id_seq\": torch.tensor(\n",
    "    [self.mod_id[mod] for mod, _ in mod_seq]),\n",
    "    \"mod_feat_seq_list\": [torch.tensor(feat).float() for\n",
    "                          _, feat in mod_seq],\n",
    "    \"input_power\": torch.tensor(p_in).float(),\n",
    "    \"output_power\": torch.tensor(p_out).float()} for\n",
    "    (mod_seq, p_in, campaign_id), p_out in zip(X, y)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Same changes are made in the RAMP ```predict``` function.\n",
    "\n",
    "Since the data format couldn't be collated easily by the ```DataLoader```\n",
    "(due to ```\"mod_id_seq\"``` having different possible lengths), we\n",
    "define a specific one which stack every components of the batch."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Power output\n",
    "    p_out = torch.stack([sample[\"output_power\"] for sample in batch])\n",
    "    # Power input\n",
    "    p_in = torch.stack([sample[\"input_power\"] for sample in batch])\n",
    "    # Module id\n",
    "    l_id_seq = [sample[\"mod_id_seq\"] for sample in batch]\n",
    "    mod_id_seq = pad_sequence(l_id_seq, batch_first=True, padding_value=-1)\n",
    "    # Module features\n",
    "    mod_feat_seq = [sample[\"mod_feat_seq_list\"] for sample in batch]\n",
    "\n",
    "    return (mod_id_seq, mod_feat_seq, p_in), p_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Learning cnosidering only single optical module data \n",
    "\n",
    "The third example we provide should help you implement models where you want to\n",
    "have different behaviours while learning based on meta data. Here we propose a\n",
    "model where the learning is done using only single module data to see how\n",
    "well it could generalize to cascade. Same scheme could be use if you want to\n",
    "have different behaviors based on the cascade identifier for example.\n",
    "\n",
    "This model is submitted under `submission/cascade_mlp_module/regressor.py`.\n",
    "\n",
    "The main differences from the previous example are in the forward function of\n",
    "the model and an exception in the backward. In this particular example\n",
    "filtering the data from the beginning would have fix the backward issue. But\n",
    "you may find some cases where checking the loss properties will be mandatory,\n",
    "in this case do a backward only when it makes sense."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if loss.requires_grad:\n",
    "    loss.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As for returning postive values at evaluation time, the use of PyTorch\n",
    "```torch.nn.Module``` argument ```training``` ease the distinction between\n",
    "train mode (calling ```self.train()``` in the ```fit``` function) and eval mode\n",
    "(calling ```self.eval()``` in the predict one) of the model. In this example,\n",
    "we want to only backpropagate through cascade of length 1\n",
    "(i.e. ```seq_len == 1```)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def forward(self, mod_id_seq, mod_feat_seq, p_in):\n",
    "    seq_len = torch.tensor(list(map(len, mod_feat_seq)))\n",
    "    p_out = p_in\n",
    "    if self.training:\n",
    "        # Training done on single modules\n",
    "        # returning p_in for cascade (no backpropagation)\n",
    "        for i, m in enumerate(self.MLPs):\n",
    "            msk = torch.mul(mod_id_seq[:, 0] == i, seq_len == 1)\n",
    "            if msk.any():\n",
    "                feats = torch.stack(\n",
    "                    [f[0] for i, f in enumerate(mod_feat_seq) if msk[i]])\n",
    "                p_out[msk] = m(torch.cat([p_out[msk], feats], dim=-1))\n",
    "        return p_out\n",
    "\n",
    "    else:\n",
    "        # Concatenate MLP to evaluate cascades\n",
    "        max_nb_mod = max(seq_len)\n",
    "        for n in range(max_nb_mod):\n",
    "            for i, m in enumerate(self.MLPs):\n",
    "                msk = torch.mul(mod_id_seq[:, n] == i, seq_len > n)\n",
    "                if msk.any():\n",
    "                    feats = torch.stack(\n",
    "                        [f[n] for i, f in enumerate(mod_feat_seq) if\n",
    "                         msk[i]])\n",
    "                    p_out[msk] = m(torch.cat([p_out[msk], feats], dim=-1))\n",
    "        return relu(p_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once again, do not hesitate to play with those examples locally to get familiar\n",
    "with RAMP and the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local testing (before submission)\n",
    "\n",
    "You submission will contain a single `regressor.py` file implementing a regressor class with a `fit` and `predict` function (scikit-learn API) as in the starting kit. You should place it in the `submission/<submission_name>` folder in your RAMP kit folder. To test your submission, go to your RAMP kit folder in a terminal and type\n",
    "```\n",
    "ramp-test --submission <submission_name>\n",
    "```\n",
    "It will train and test your submission much like we did it above in this notebook, and print the foldwise and summary scores. You can try it also in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;178m\u001b[1mTesting Optical network modelling\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading train and test files from ./data/ ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading cv ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mTraining submissions\\starting_kit ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 0\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   EM99    RMSE   MEM      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m1.097\u001b[0m  \u001b[38;5;150m0.0808\u001b[0m  \u001b[38;5;150m4.30\u001b[0m  \u001b[38;5;150m0.277946\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m1.229\u001b[0m  \u001b[38;5;105m0.1199\u001b[0m  \u001b[38;5;105m2.10\u001b[0m  \u001b[38;5;105m0.261952\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.284\u001b[0m  \u001b[38;5;218m0.1250\u001b[0m  \u001b[38;5;218m2.39\u001b[0m  \u001b[38;5;218m0.015651\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 1\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   EM99    RMSE   MEM      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m1.108\u001b[0m  \u001b[38;5;150m0.0834\u001b[0m  \u001b[38;5;150m3.90\u001b[0m  \u001b[38;5;150m0.102995\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m1.284\u001b[0m  \u001b[38;5;105m0.1265\u001b[0m  \u001b[38;5;105m1.72\u001b[0m  \u001b[38;5;105m0.196524\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.276\u001b[0m  \u001b[38;5;218m0.1245\u001b[0m  \u001b[38;5;218m2.40\u001b[0m  \u001b[38;5;218m0.010556\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 2\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   EM99    RMSE   MEM      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m1.091\u001b[0m  \u001b[38;5;150m0.0818\u001b[0m  \u001b[38;5;150m3.62\u001b[0m  \u001b[38;5;150m0.116234\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m1.279\u001b[0m  \u001b[38;5;105m0.1277\u001b[0m  \u001b[38;5;105m2.10\u001b[0m  \u001b[38;5;105m0.189690\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.281\u001b[0m  \u001b[38;5;218m0.1249\u001b[0m  \u001b[38;5;218m2.38\u001b[0m  \u001b[38;5;218m0.011603\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 3\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   EM99    RMSE   MEM      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m1.099\u001b[0m  \u001b[38;5;150m0.0816\u001b[0m  \u001b[38;5;150m3.94\u001b[0m  \u001b[38;5;150m0.199146\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m1.215\u001b[0m  \u001b[38;5;105m0.1247\u001b[0m  \u001b[38;5;105m1.73\u001b[0m  \u001b[38;5;105m0.259609\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.291\u001b[0m  \u001b[38;5;218m0.1252\u001b[0m  \u001b[38;5;218m2.38\u001b[0m  \u001b[38;5;218m0.016765\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 4\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   EM99    RMSE   MEM      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m1.131\u001b[0m  \u001b[38;5;150m0.0830\u001b[0m  \u001b[38;5;150m3.89\u001b[0m  \u001b[38;5;150m0.121125\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m1.259\u001b[0m  \u001b[38;5;105m0.1170\u001b[0m  \u001b[38;5;105m2.10\u001b[0m  \u001b[38;5;105m0.247806\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.278\u001b[0m  \u001b[38;5;218m0.1244\u001b[0m  \u001b[38;5;218m2.37\u001b[0m  \u001b[38;5;218m0.013509\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 5\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   EM99    RMSE   MEM      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m1.100\u001b[0m  \u001b[38;5;150m0.0809\u001b[0m  \u001b[38;5;150m3.33\u001b[0m  \u001b[38;5;150m0.106346\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m1.226\u001b[0m  \u001b[38;5;105m0.1257\u001b[0m  \u001b[38;5;105m2.13\u001b[0m  \u001b[38;5;105m0.214132\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.286\u001b[0m  \u001b[38;5;218m0.1251\u001b[0m  \u001b[38;5;218m2.39\u001b[0m  \u001b[38;5;218m0.010903\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 6\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   EM99    RMSE   MEM      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m1.123\u001b[0m  \u001b[38;5;150m0.0836\u001b[0m  \u001b[38;5;150m3.87\u001b[0m  \u001b[38;5;150m0.214350\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m1.274\u001b[0m  \u001b[38;5;105m0.1217\u001b[0m  \u001b[38;5;105m2.10\u001b[0m  \u001b[38;5;105m0.223215\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.279\u001b[0m  \u001b[38;5;218m0.1247\u001b[0m  \u001b[38;5;218m2.37\u001b[0m  \u001b[38;5;218m0.009213\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 7\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   EM99    RMSE   MEM      time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m1.106\u001b[0m  \u001b[38;5;150m0.0822\u001b[0m  \u001b[38;5;150m3.86\u001b[0m  \u001b[38;5;150m0.103886\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m1.267\u001b[0m  \u001b[38;5;105m0.1241\u001b[0m  \u001b[38;5;105m2.08\u001b[0m  \u001b[38;5;105m0.239560\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.284\u001b[0m  \u001b[38;5;218m0.1248\u001b[0m  \u001b[38;5;218m2.38\u001b[0m  \u001b[38;5;218m0.011794\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mMean CV scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore            EM99              RMSE           MEM        time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m1.107\u001b[0m \u001b[38;5;150m\u001b[38;5;150m\u001b[38;5;150m\u001b[38;5;150m±\u001b[0m\u001b[0m\u001b[0m\u001b[0m \u001b[38;5;150m0.0127\u001b[0m    \u001b[38;5;150m0.0822\u001b[0m \u001b[38;5;150m\u001b[38;5;150m\u001b[38;5;150m\u001b[38;5;150m±\u001b[0m\u001b[0m\u001b[0m\u001b[0m \u001b[38;5;150m0.001\u001b[0m  \u001b[38;5;150m3.84\u001b[0m \u001b[38;5;150m\u001b[38;5;150m\u001b[38;5;150m\u001b[38;5;150m±\u001b[0m\u001b[0m\u001b[0m\u001b[0m \u001b[38;5;150m\u001b[38;5;150m0.2\u001b[0m59\u001b[0m  \u001b[38;5;150m0.2\u001b[0m \u001b[38;5;150m\u001b[38;5;150m\u001b[38;5;150m\u001b[38;5;150m±\u001b[0m\u001b[0m\u001b[0m\u001b[0m \u001b[38;5;150m0.06\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m1.254\u001b[0m \u001b[38;5;105m\u001b[38;5;105m\u001b[38;5;105m\u001b[38;5;105m±\u001b[0m\u001b[0m\u001b[0m\u001b[0m \u001b[38;5;105m0.0251\u001b[0m  \u001b[38;5;105m0.1234\u001b[0m \u001b[38;5;105m\u001b[38;5;105m\u001b[38;5;105m\u001b[38;5;105m±\u001b[0m\u001b[0m\u001b[0m\u001b[0m \u001b[38;5;105m0.00337\u001b[0m  \u001b[38;5;105m2.01\u001b[0m \u001b[38;5;105m\u001b[38;5;105m\u001b[38;5;105m\u001b[38;5;105m±\u001b[0m\u001b[0m\u001b[0m\u001b[0m \u001b[38;5;105m0.163\u001b[0m  \u001b[38;5;105m0.2\u001b[0m \u001b[38;5;105m\u001b[38;5;105m\u001b[38;5;105m\u001b[38;5;105m±\u001b[0m\u001b[0m\u001b[0m\u001b[0m \u001b[38;5;105m0.03\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.282\u001b[0m \u001b[38;5;218m\u001b[38;5;218m\u001b[38;5;218m\u001b[38;5;218m±\u001b[0m\u001b[0m\u001b[0m\u001b[0m \u001b[38;5;218m\u001b[38;5;218m\u001b[38;5;218m0.0\u001b[0m\u001b[0m045\u001b[0m  \u001b[38;5;218m0.1248\u001b[0m \u001b[38;5;218m\u001b[38;5;218m\u001b[38;5;218m\u001b[38;5;218m±\u001b[0m\u001b[0m\u001b[0m\u001b[0m \u001b[38;5;218m\u001b[38;5;218m\u001b[38;5;218m0.0\u001b[0m\u001b[0m0027\u001b[0m  \u001b[38;5;218m2.38\u001b[0m \u001b[38;5;218m\u001b[38;5;218m\u001b[38;5;218m\u001b[38;5;218m±\u001b[0m\u001b[0m\u001b[0m\u001b[0m \u001b[38;5;218m\u001b[38;5;218m\u001b[38;5;218m0.0\u001b[0m\u001b[0m09\u001b[0m   \u001b[38;5;218m\u001b[38;5;218m0.0\u001b[0m\u001b[0m \u001b[38;5;218m\u001b[38;5;218m\u001b[38;5;218m\u001b[38;5;218m±\u001b[0m\u001b[0m\u001b[0m\u001b[0m \u001b[38;5;218m\u001b[38;5;218m0.0\u001b[0m\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mBagged scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   EM99    RMSE   MEM\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m1.271\u001b[0m  \u001b[38;5;105m0.1256\u001b[0m  \u001b[38;5;105m2.10\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.283\u001b[0m  \u001b[38;5;218m0.1248\u001b[0m  \u001b[38;5;218m2.38\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ramp-test --submission starting_kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "1. First you will need to sign up at the [RAMP site](https://ecs-90-84-188-77.compute.prod-cloud-ocb.orange-business.com). Your team will be approved shortly by a system admin who will check that you communicated your team nick and composition to BeMyApp.\n",
    "2. You will then need a second sign-up, this time for the [optical network challenge](https://ecs-90-84-188-77.compute.prod-cloud-ocb.orange-business.com/events/optical_network_modelling_hackaton). If your site sign up was approved in the previous point, you should see a \"Join event\" button on the right of the top menu. This request will also be approved by a site admin.\n",
    "3. Once you are signed up, you can start submitting (once a day). If you are happy with your local scores, copy-paste your submission at the [sandbox](https://ecs-90-84-188-77.compute.prod-cloud-ocb.orange-business.com/events/optical_network_modelling_hackaton/sandbox), press \"submit now\", name your submission, then give credits to which other submission you used (in the collaborative phase you will see only your own submissions in the list.\n",
    "4. Your submission will be sent to train. It will either come back with an error or will be scored. You can follow the status at [my submissions](https://ecs-90-84-188-77.compute.prod-cloud-ocb.orange-business.com/events/optical_network_modelling_hackaton/my_submissions).\n",
    "5. If there is an error, click on the error to see the trace. You can resubmit a failed submission **under the same name**, this will not count in your daily quota.\n",
    "6. There is no way to delete trained submissions. In exceptional cases we can stop a submission that hasn't been scored yet so you can resubmit. We strongly suggest to finish training at least one fold locally (using `ramp-test`) before submitting so you can estimate the training time.\n",
    "7. You can follow the scores of the other participants at the [public leaderboard](https://ecs-90-84-188-77.compute.prod-cloud-ocb.orange-business.com/events/optical_network_modelling_hackaton/leaderboard).\n",
    "8. The public [competition leaderboard](https://ecs-90-84-188-77.compute.prod-cloud-ocb.orange-business.com/events/optical_network_modelling_hackaton/competition_leaderboard) displays the top submission (according to the public score) of each participant. You can change which of your submission enters the competition by pulling out the top submission. Click on the particular submission at [my submissions](https://ecs-90-84-188-77.compute.prod-cloud-ocb.orange-business.com/events/optical_network_modelling_hackaton/my_submissions) and click on the yellow button. The operation is reversible as many times you want, even after the competition deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact\n",
    "\n",
    "You can contact the organizers in the Slack of the challenge, join by [clicking here](https://join.slack.com/t/huaweiramp/shared_invite/zt-i5hqij3l-ufzyUJgKNJA407sWNB1QDA). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
