{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huawei Research France\n",
    "\n",
    "## Optical network modelling RAMP: cascading regressors\n",
    "\n",
    "### Predict the output of a 32-channel optical network from its input and side information about the sequence of network components\n",
    "\n",
    "_Balázs Kégl, Ludovic Dos Santos, Hartmut Hafermann (Huawei Research, Noah's Ark and Optical Laboratories, France)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Building system models and simulators is a relatively new application area of machine learning. These models can replace expensive experimentation and accelerate design. This year's Huawei France hackathon falls into this category: we will ask participants to learn a model of optical networks from (real) data taken in our Optical Lab. It is a **32-output nonlinear regression problem**, with non-classical challenges:\n",
    "1. **Transfer learning**: the training and test data will be different: at training we will provide data measured at internal points of the network, whereas we will test the models only for the full cascades, taken on a network with different characteristics from the training network.\n",
    "2. **Non-standard input**: besides input-output data, we will also provide variable-length side information about the network components which may greatly help the transfer from the trianing network to the test network.\n",
    "3. **Scoring metrics** will be a nonstandard measure of the worst 1% test instances according to their relative prediction error.\n",
    "\n",
    "### Context\n",
    "\n",
    "In optical transmission links, information is transmitted through optical fibers. The available transmission bandwidth is equally divided into a fixed number of slots or channels, 32 in this data challenge. Each channel can be used to transmit a beam of laser light at a fixed frequency, modulated by an information carrying signal, such that it occupies its assigned bandwidth. Each of these channels can be used to independently transmit information through the fiber.\n",
    "\n",
    "Even though modern fibers are highly transparent, the **loss of signal strength** is not negligible and can be as high as a factor of 100 = 20[dB](https://en.wikipedia.org/wiki/Decibel) for 100km of fiber. Fiber transmission links therefore typically consist of a **cascade of alternating optical amplifiers and fibers**. Optical amplifiers compensate for the losses by amplifying the optical signal directly inside the fiber, without the need to convert it into an electrical signal. One of the most widely used type of amplifier is the [Erbium-doped fiber amplifier (EDFA)](https://en.wikipedia.org/wiki/Optical_amplifier#Erbium-doped_optical_fiber_amplifiers). In detail, optical networks contain EDFAs, single mode fibers (SMFs) and variable optical attenuators (VOAs). The dashed lines in the following figure indicate the positions at which the signal is measured.\n",
    "<img src=\"link.png\">\n",
    "\n",
    "EDFA implements a **32-input 32-output function**. Computer models of this function are highly useful when telecom providers design  optical networks since these models allow them to optimize the network before building it. In principle, EDFA amplifies its 32 input signals linearly, controlled by two parameters (set by the operator of the network), its gain and tilt. In practice, the **amplification is nonlinear** and it also **depends on which channels are switched on and off**. Generalizing to unseen on/off configurations is important since network operators regularly add or drop channels according to transmission demand. There is no simple physical model of this combinatorial function, thus the aim of our project: explore using machine learning techniques that can be learned on a small subsample of the combinatorial space.\n",
    "\n",
    "### The data\n",
    "\n",
    "The data is taken from lab measurements of the cascade network shown in the figure above. For the purpose of this RAMP, we can abstract the transmission cascade as a concatenation of eight modules:\n",
    "<img src=\"cascade.png\">\n",
    "Each module is either an EDFA or a fiber (SMF+VOA), described by a small metadata vector whose format depands on the module type. Each **training instance will be a subcascade** $(i,j)$ with input signal $P_i \\in \\mathbb{R}^{32}$ and output signal $P_j \\in \\mathbb{R}^{32}$ and a sequence of module metadata $(m_i, \\ldots, m_{j-1})$. Each **test instance will be a full cascade** $(0,8)$ with input signal $P_0 \\in \\mathbb{R}^{32}$ and output signal $P_8 \\in \\mathbb{R}^{32}$ and a sequence of module metadata $(m_1, \\ldots, m_7)$. To mimic real-life scenarios, the module metadata of the test cascade will be different from the \n",
    "module metadata of the training cascade (although the module types in the sequence will be the same). Each training and test instance will be generated by a random channel on/off configuration, cascaded through the network (so subcascade instances will not be independent). Again, training and test configurations will be different.\n",
    "\n",
    "### The scoring metrics\n",
    "\n",
    "We will report a classical RMSE score on the submissions, but the official ranking score will be EM99, designed by the optical experts to measure the 99 percentile of the error measured in dB (relative error).  \n",
    "\n",
    "\n",
    "## Competition rules\n",
    "\n",
    "The rules may be adjusted before the start of the challenge, November 4 2020.\n",
    "\n",
    "[//]: # \"* Submissions will be trained on a time series of roughly 5000 time steps and tested on a time series of roughly 20000 time steps.\" \n",
    "* The competition will end on November 13, 2020 at 19h UTC (20h in Paris).\n",
    "* All models will be trained on the same cloud server allowing 4 CPUs (with shared memory of 128GB RAM).\n",
    "* Participants will be given a total of 20 machine hours. Submissions of a given participant will be ordered by submission timestamp. We will make an attempt to train all submissions, but starting from (and including) the first submission that makes the participant's total training time exceed 20 hours, all submissions will be disqualified from the competition (but can enter into the collaborative phase). Testing time will not count towards the limit. Training time will be displayed on the leaderboard for all submissions, rounded to second. If a submission raises an exception, its training time will not count towards the total.\n",
    "* There is a timeout of 1 day between submissions.\n",
    "* Submissions submitted after the end of the competition will not qualify for prizes.\n",
    "* The public leaderboard will display validation scores running a cross-validation. The official scores will be calculated on the hidden test set and will be published after the closing of the competition. We will rank submissions according to their EM99 score.\n",
    "* The organizers will do their best so that the provided backend runs flawlessly. We will communicate with participants in case of concerns and will try to resolve all issues, but we reserve the right to make unilateral decisions in specific cases, not covered by this set of minimal rules.\n",
    "* The organizers reserve the right to disqualify any participant found to violate the fair competitive spirit of the challenge. Possible reasons, without being exhaustive, are multiple accounts, attempts to access the test data, etc.\n",
    "* The challenge is essentially an individual contest, so there is no way to form official teams. Participants can form teams outside the platform before submitting any model individually, and submit on a single team member's account. However, submitting on one's own and participating in such a team at the same time is against the \"no multiple accounts\" rule, so, if discovered, may lead to disqualification.\n",
    "* Participants retain copyright on their submitted code and grant reuse under BSD 3-Clause License.\n",
    "\n",
    "Participants accept these rules automatically when making a submission at the RAMP site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
