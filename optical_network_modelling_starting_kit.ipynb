{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huawei Research France\n",
    "\n",
    "## Optical network modelling RAMP: cascading regressors\n",
    "\n",
    "### Predict the output of a 32-channel optical network from its input and side information about the sequence of network components\n",
    "\n",
    "_Balázs Kégl, Ludovic Dos Santos, Hartmut Hafermann (Huawei Research, Noah's Ark and Optical Laboratories, France)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Building system models and simulators is a relatively new application area of machine learning. These models can replace expensive experimentation and accelerate design. This year's Huawei France hackathon falls into this category: we will ask participants to learn a model of optical networks from (real) data taken in our Optical Lab. It is a **32-output nonlinear regression problem**, with non-classical challenges:\n",
    "1. **Transfer learning**: the training and test data will be different: at training we will provide data measured at internal points of the network, whereas we will test the models only for the full cascades, taken on a network with different characteristics from the training network.\n",
    "2. **Non-standard input**: besides input-output data, we will also provide side variable-length information about the network components which may greatly help the transfer from the trianing network to the test network.\n",
    "3. **Scoring metrics** will be a nonstandard measure of the worst 5\\% test instances according to their relative prediction error.\n",
    "\n",
    "### Context\n",
    "\n",
    "In optical transmission links, information is transmitted through optical fibers. The available transmission bandwidth is equally divided into a fixed number of slots or channels, 32 in this data challenge. Each channel can be used to transmit a beam of laser light at a fixed frequency, modulated by an information carrying signal, such that it occupies its assigned bandwidth. Each of these channels can be used to independently transmit information through the fiber.\n",
    "\n",
    "Even though modern fibers are highly transparent, the **loss of signal strength** is not negligible and can be as high as a factor of 100 = 20[dB](https://en.wikipedia.org/wiki/Decibel) for 100km of fiber. Fiber transmission links therefore typically consist of a **cascade of alternating optical amplifiers and fibers**. Optical amplifiers compensate for the losses by amplifying the optical signal directly inside the fiber, without the need to convert it into an electrical signal. One of the most widely used type of amplifier is the [Erbium-doped fiber amplifier (EDFA)](https://en.wikipedia.org/wiki/Optical_amplifier#Erbium-doped_optical_fiber_amplifiers). In detail, optical networks contain EDFAs, single mode fibers (SMFs) and variable optical attenuators (VOAs). The dashed lines in the following figure indicate the positions at which the signal is measured.\n",
    "<img src=\"link.png\">\n",
    "\n",
    "EDFA implements a **32-input 32-output function**. Computer models of this function are highly useful when telecom providers design  optical networks since these models allow them to optimize the network before building it. In principle, EDFA amplifies its 32 input signals linearly, controlled by two parameters (set by the operator of the network), its gain and tilt. In practice, the **amplification is nonlinear** and it also **depends on which channels are switched on and off**. Generalizing to unseen on/off configurations is important since network operators regularly add or drop channels according to transmission demand. There is no simple physical model of this combinatorial function, thus the aim of our project: explore using machine learning techniques that can be learned on a small subsample of the combinatorial space.\n",
    "\n",
    "### The data\n",
    "\n",
    "The data is taken from lab measurements of the cascade network shown in the figure above. For the purpose of this RAMP, we can abstract the transmission cascade as a concatenation of eight modules:\n",
    "<img src=\"cascade.png\">\n",
    "Each module is either an EDFA or a fiber (SMF+VOA), described by a small metadata vector whose format depands on the module type. Each **training instance will be a subcascade** $(i,j)$ with input signal $P_i \\in \\mathbb{R}^{32}$ and output signal $P_j \\in \\mathbb{R}^{32}$ and a sequence of module metadata $(m_i, \\ldots, m_{j-1})$. Each **test instance will be a full cascade** $(0,8)$ with input signal $P_0 \\in \\mathbb{R}^{32}$ and output signal $P_8 \\in \\mathbb{R}^{32}$ and a sequence of module metadata $(m_1, \\ldots, m_7)$. To mimic real-life scenarios, the module metadata of the test cascade will be different from the \n",
    "module metadata of the training cascade (although the module types in the sequence qill be the same). Each training and test instance will be generated by a random channel on/off configuration, cascaded through the network (so subcascade instances will not be independent). Again, training and test configurations will be different.\n",
    "\n",
    "### The scoring metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
